{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeHCmvunsbaWMFIOGcfK6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yebyyy/English-Premier-League-2023-2024-Prediction/blob/main/Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This code is for scraping the data for the current season of English Premier League"
      ],
      "metadata": {
        "id": "3XyxPJOu0Vco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "5g-pKx1IxYxl"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "YMVSVHK1ytxJ"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dsTPQudoTijs"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
      ],
      "metadata": {
        "id": "gCP0sWE9xvie"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = requests.get(standings_url)"
      ],
      "metadata": {
        "id": "Uc79WNiD0Ud-"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "tBy3RyFH0kV_"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(data.text)"
      ],
      "metadata": {
        "id": "kBcXkpggZIYi"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now we need give the soup object something to select.\n",
        "Since everything is inside the table html object, we need to select it and then get everything anchor tags for the clubs."
      ],
      "metadata": {
        "id": "3_fHm32bcxaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zdk_ug881tU",
        "outputId": "935f6315-1896-4e26-b0aa-0409806c364c"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [429]>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting the table using css selector\n",
        "standings_table = soup.select('tables.stats_table')[0] # .stats_table is the class name"
      ],
      "metadata": {
        "id": "W7sWu-ZgZYWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "27862ecf-7be9-46c7-c490-0f0559f6073f"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-627c3c5279ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# selecting the table using css selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstandings_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table.stats_table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# .stats_table is the class name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find all the <a>(the clubs) in the standings table\n",
        "links = standings_table.find_all(\"a\") # find_all only finds tags"
      ],
      "metadata": {
        "id": "wArQZpOmeIEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# links should actually contain all the links\n",
        "links = [l.get(\"href\") for l in links]"
      ],
      "metadata": {
        "id": "a4jWBcsPe71y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# links should actually contain the links that have clubs\n",
        "links = [l for l in links if \"/squads/\" in l]\n",
        "links"
      ],
      "metadata": {
        "id": "uxUeaABMfSDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since the links only have the subdomain, we should include the first half of the url as well\n",
        "team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
        "team_urls"
      ],
      "metadata": {
        "id": "hOXZxE32fnI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Pandas and Requests to extract match stats: Using a single team as an example"
      ],
      "metadata": {
        "id": "e2Ku8_jogWO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "team_url_first = team_urls[0]\n",
        "team_url_first"
      ],
      "metadata": {
        "id": "5FlvXaWVgc9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_data = requests.get(team_url_first)"
      ],
      "metadata": {
        "id": "VceJh5T_TQ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use pandas for the parsing and read only the table called scores and fixtures since we only care about the data there"
      ],
      "metadata": {
        "id": "GvYKJOI5UnD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches_first_team = pd.read_html(first_team_data.text, match=\"Scores & Fixtures\")"
      ],
      "metadata": {
        "id": "7isBH2ovULtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a list, we want a pandas dataFrame, therefore we get the first element from this list"
      ],
      "metadata": {
        "id": "p6rGw0rzXwlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches_first_team = matches_first_team[0]"
      ],
      "metadata": {
        "id": "I1BfBGOEUaSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now we also care about the shooting data, so we continue using the same team for the example"
      ],
      "metadata": {
        "id": "Ep2Ub8dZYWAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the shooting page is now just a URL in an anchor in the webpage of the club page we were working on, we find all the links and keep the one that has shooting in it"
      ],
      "metadata": {
        "id": "PXS-eCB1ZKuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup_for_first_team = BeautifulSoup(first_team_data.text)"
      ],
      "metadata": {
        "id": "7kT94OH_X494"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link_for_first_team = soup_for_first_team.find_all(\"a\")"
      ],
      "metadata": {
        "id": "dMejgUnpZqi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link_for_first_team = [l.get(\"href\") for l in link_for_first_team]"
      ],
      "metadata": {
        "id": "69kr8Y5RYBe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link_for_first_team = [l for l in link_for_first_team if l and \"all_comps/shooting/\" in l]\n",
        "link_for_first_team"
      ],
      "metadata": {
        "id": "MbXKAwfVYLVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_shooting_data = requests.get(f\"https://fbref.com{link_for_first_team[0]}\")"
      ],
      "metadata": {
        "id": "-bisl-QdYhKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_shooting_frame = pd.read_html(first_team_shooting_data.text, match='Shooting')\n",
        "first_team_shooting_frame = first_team_shooting_frame[0]"
      ],
      "metadata": {
        "id": "BPCONxniZ2Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaning and merging data in pandas"
      ],
      "metadata": {
        "id": "fh4JzjOXlOaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't want the multilevel index, so just drop that"
      ],
      "metadata": {
        "id": "S5IR6EhPliHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_shooting_frame.columns = first_team_shooting_frame.columns.droplevel()"
      ],
      "metadata": {
        "id": "yHsLyBj2Z6qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_shooting_frame.head()"
      ],
      "metadata": {
        "id": "zbXB5fVXoSAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_frame = matches_first_team.merge(first_team_shooting_frame[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
        "first_team_frame.head()"
      ],
      "metadata": {
        "id": "WffYicYLmGQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This just added additional columns in the end of the frame"
      ],
      "metadata": {
        "id": "ASxpaPDPonJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches_first_team.shape"
      ],
      "metadata": {
        "id": "YOHmWuOdnZ1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_team_shooting_frame.shape"
      ],
      "metadata": {
        "id": "MKrG4_-Ho6ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we should scrape the data for multiple seasons and for all of the teams existed in the English Premier League"
      ],
      "metadata": {
        "id": "KwM-RYPipmOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = list(range(2024, 2021, -1))\n",
        "years"
      ],
      "metadata": {
        "id": "A7GjLTgwo9J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# several DataFrames and each DataFrame contains the match log for a team\n",
        "all_matches = []"
      ],
      "metadata": {
        "id": "jmQH-TZpqRPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for year in years:\n",
        "  # get the links to the teams through the table.stats_table\n",
        "  data = requests.get(standings_url)\n",
        "  soup = BeautifulSoup(data.text)\n",
        "  table = soup.select(\"table.stats_table\")[0]\n",
        "  links = standings_table.find_all(\"a\")\n",
        "  links = [l.get(\"href\") for l in links]\n",
        "  links = [l for l in links if \"/squads/\" in l]\n",
        "\n",
        "  previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
        "  standings_url = f\"https://fbref.com{previous_season}\"\n",
        "\n",
        "  team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
        "  for team in team_urls:\n",
        "    team_name = team.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
        "    data = requests.get(team)\n",
        "    # read the table that has the Scores and Fixtures\n",
        "    matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
        "    # get the link to the scoring data\n",
        "    soup = BeautifulSoup(data.text)\n",
        "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
        "    links = [l for l in links if l and \"all_comps/shooting/\" in l]\n",
        "    data = requests.get(f\"https://fbref.com{links[0]}\")\n",
        "    shooting = pd.read_html(data.text, match='Shooting')[0]\n",
        "    shooting.columns = shooting.columns.droplevel()\n",
        "\n",
        "    try:\n",
        "      team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
        "    # for some teams the shooting table is not available\n",
        "    except ValueError:\n",
        "      continue\n",
        "\n",
        "    # filter by competition and add column indicating years and team names\n",
        "    team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
        "    team_data[\"Season\"] = year\n",
        "    team_data[\"Team\"] = team_name\n",
        "    all_matches.append(team_data)\n",
        "    time.sleep(3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AHgFShRzrNeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_df = pd.concat(all_matches)\n",
        "match_df.columns = [c.lower() for c in match_df.columns]"
      ],
      "metadata": {
        "id": "0_Cpxk1zsxzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_df.to_csv(\"matches.csv\")"
      ],
      "metadata": {
        "id": "CfOVA-WkzZz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}